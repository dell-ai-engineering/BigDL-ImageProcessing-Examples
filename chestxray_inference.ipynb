{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make notebook fill the whole browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested with :\n",
    "# bigdl 0.7.2\n",
    "# analytics-zoo 0.4.0\n",
    "# pyspark 2.1.0\n",
    "\n",
    "from bigdl.nn.layer import Model\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.models.image.imageclassification import *\n",
    "from zoo.pipeline.nnframes import *\n",
    "from zoo.pipeline.api.net import Net\n",
    "from zoo.pipeline.api.keras.models import Sequential\n",
    "from zoo.pipeline.api.keras.layers import *\n",
    "from zoo.pipeline.api.keras.metrics import AUC\n",
    "from zoo.pipeline.api.net import Net\n",
    "from zoo.pipeline.nnframes import NNEstimator\n",
    "from zoo.pipeline.api.keras.objectives import BinaryCrossEntropy\n",
    "\n",
    "sparkConf = create_spark_conf().setAppName(\"ChestXray_Inference\")\n",
    "sc = init_nncontext(sparkConf)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data location\n",
    "test_image_path = \"hdfs:///datasets/xray/all_images/00000001_000.png\"\n",
    "label_path = \"hdfs:///datasets/xray/Data_Entry_2017.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "label_texts = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\", \"Pneumonia\",\n",
    "               \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]\n",
    "label_map = {k: v for v, k in enumerate(label_texts)}\n",
    "\n",
    "def text_to_label(text):\n",
    "    arr = [0.0] * len(label_texts)\n",
    "    for l in text.split(\"|\"):\n",
    "        if l != \"No Finding\":\n",
    "            arr[label_map[l]] = 1.0\n",
    "    return arr\n",
    "\n",
    "label_length = len(label_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Image_Index: string (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = false)\n",
      " |    |-- width: integer (nullable = false)\n",
      " |    |-- nChannels: integer (nullable = false)\n",
      " |    |-- mode: integer (nullable = false)\n",
      " |    |-- data: binary (nullable = false)\n",
      " |-- Finding_Labels: string (nullable = true)\n",
      " |-- label: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "None\n",
      "+----------------+--------------------+--------------+--------------------+\n",
      "|     Image_Index|               image|Finding_Labels|               label|\n",
      "+----------------+--------------------+--------------+--------------------+\n",
      "|00000001_000.png|[hdfs://gnamenode...|  Cardiomegaly|[0.0, 1.0, 0.0, 0...|\n",
      "+----------------+--------------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create inference dataframe\n",
    "getLabel = udf(lambda x: text_to_label(x), ArrayType(DoubleType()))\n",
    "getName = udf(lambda row: os.path.basename(row[0]), StringType())\n",
    "test_imageDF = NNImageReader.readImages(test_image_path, sc, resizeH=256, resizeW=256, image_codec=1)\\\n",
    "                .withColumn(\"Image Index\", getName(col('image')))\n",
    "imageDF = test_imageDF.withColumnRenamed('Image Index', 'Image_Index')\n",
    "labelDF = sqlContext.read.option('timestampFormat', 'yyyy/MM/dd HH:mm:ss ZZ')\\\n",
    "            .load(label_path, format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\\\n",
    "            .select(\"Image Index\", \"Finding Labels\")\\\n",
    "            .withColumn(\"label\", getLabel(col('Finding Labels')))\\\n",
    "            .withColumnRenamed('Image Index', 'Image_Index')\n",
    "labelDF1 = labelDF.withColumnRenamed('Image Index', 'Image_Index')\\\n",
    "            .withColumnRenamed('Finding Labels', 'Finding_Labels')\n",
    "trainDF = imageDF.join(labelDF1, on=\"Image_Index\", how=\"inner\")\n",
    "\n",
    "print(trainDF.printSchema())\n",
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load resnet-50 analytics zoo keras model\n",
    "resnet_zoo_model = Net.load(\"hdfs:///user/leelau/xray/save_model/model.bigdl\", \"hdfs:///user/leelau/xray/save_model/model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zoo.pipeline.api.keras.base.ZooKerasLayer"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resnet_zoo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createRowToImageFeature\n",
      "creating: createImageCenterCrop\n",
      "creating: createImageChannelNormalize\n",
      "creating: createImageMatToTensor\n",
      "creating: createImageFeatureToTensor\n",
      "creating: createChainedPreprocessing\n",
      "creating: createTensorToSample\n",
      "creating: createChainedPreprocessing\n",
      "creating: createNNModel\n",
      "+----------------+--------------------+--------------+--------------------+--------------------+\n",
      "|     Image_Index|               image|Finding_Labels|               label|          prediction|\n",
      "+----------------+--------------------+--------------+--------------------+--------------------+\n",
      "|00000001_000.png|[hdfs://gnamenode...|  Cardiomegaly|[0.0, 1.0, 0.0, 0...|[0.051492076, 0.9...|\n",
      "+----------------+--------------------+--------------+--------------------+--------------------+\n",
      "\n",
      "None\n",
      "('length of prediction array : ', 14)\n",
      "('prediction : ', [0.051492076367139816, 0.9890044331550598, 0.23523545265197754, 0.11708319187164307, 0.021687369793653488, 0.030919406563043594, 0.01281912624835968, 0.013840589672327042, 0.015496516600251198, 0.010675224475562572, 0.010313905775547028, 0.033583492040634155, 0.038701385259628296, 0.019549697637557983])\n"
     ]
    }
   ],
   "source": [
    "# inference using the resnet model as-is when it is used on trainDF\n",
    "def predict(model, inputdf, image_feature_col = \"image\", batchsize=4):\n",
    "    \"\"\"\n",
    "    Predict output of when inputdf is passed through model\n",
    "    \"\"\"\n",
    "    transformer = ChainedPreprocessing([\n",
    "        RowToImageFeature(),\n",
    "        ImageCenterCrop(224, 224),\n",
    "        ImageChannelNormalize(123.68, 116.779, 103.939),\n",
    "        ImageMatToTensor(),\n",
    "        ImageFeatureToTensor()])\n",
    "    classifier_model = NNModel(model, transformer).setFeaturesCol(image_feature_col)\\\n",
    "                        .setBatchSize(batchsize)\n",
    "    output = classifier_model.transform(inputdf)\n",
    "    return output\n",
    "\n",
    "def show_prediction_output(predDF):\n",
    "    \"\"\"\n",
    "    Display the output size and array\n",
    "    \"\"\"\n",
    "    print(predDF.show(1))\n",
    "    print(\"length of prediction array : \", len(predDF.collect()[0].prediction))\n",
    "    print(\"prediction : \", predDF.collect()[0].prediction)\n",
    "\n",
    "    \n",
    "# check output of the resnet model as-is using the inference dataframe\n",
    "output = predict(resnet_zoo_model, trainDF)\n",
    "show_prediction_output(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
