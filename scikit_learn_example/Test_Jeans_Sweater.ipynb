{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the high level transfer learning APIs, you can easily customize pretrained models for feature extraction or fine-tuning. \n",
    "\n",
    "In this notebook, we will use a pre-trained Inception_V1 model. But we will operate on the pre-trained model to freeze first few layers, replace the classifier on the top, then fine tune the whole model. And we use the fine-tuned model to solve the dogs-vs-cats classification problem,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the dogs-vs-cats datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training dataset from https://www.kaggle.com/c/dogs-vs-cats and extract it. \n",
    "\n",
    "The following commands copy about 1100 images of cats and dogs into demo/cats and demo/dogs separately. \n",
    "```shell\n",
    "mkdir -p demo/dogs\n",
    "mkdir -p demo/cats\n",
    "cp train/cat.7* demo/cats\n",
    "cp train/dog.7* demo/dogs```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the pre-trained Inception-V1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pre-trained Inception-V1 model from [Zoo](https://s3-ap-southeast-1.amazonaws.com/bigdl-models/imageclassification/imagenet/bigdl_inception-v1_imagenet_0.4.0.model) \n",
    " Alternatively, user may also download pre-trained caffe/Tensorflow/keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /usr/lib64/python2.7/site-packages/bigdl/share/lib/bigdl-0.6.0-jar-with-dependencies.jar to BIGDL_JARS\n",
      "Prepending /usr/lib64/python2.7/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
      "Adding /usr/lib/python2.7/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.6.0-spark_2.1.0-0.2.0-jar-with-dependencies.jar to BIGDL_JARS\n",
      "Prepending /usr/lib/python2.7/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/usr/lib64/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/usr/lib64/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/lib64/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/usr/lib64/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/lib64/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from bigdl.nn.criterion import CrossEntropyCriterion\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.pipeline.api.keras.layers import Dense, Input, Flatten\n",
    "from zoo.pipeline.api.keras.models import *\n",
    "from zoo.pipeline.api.net import *\n",
    "from zoo.pipeline.nnframes import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/utils/__init__.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/lib64/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/usr/lib64/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/usr/lib64/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/usr/lib64/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/usr/lib64/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/usr/lib64/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/usr/lib64/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/usr/lib64/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/usr/lib64/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/usr/lib64/python2.7/site-packages/scipy/optimize/_trlib/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._trlib import TRLIBQuadraticSubproblem\n",
      "/usr/lib64/python2.7/site-packages/scipy/optimize/_numdiff.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/usr/lib64/python2.7/site-packages/scipy/stats/_continuous_distns.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/usr/lib64/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/lib64/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/usr/lib64/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/lib64/python2.7/site-packages/sklearn/metrics/pairwise.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n"
     ]
    }
   ],
   "source": [
    "from bigdl.nn.criterion import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType, ArrayType\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.pipeline.api.keras.layers import Input, Flatten, Dense\n",
    "from zoo.pipeline.api.keras.models import *\n",
    "from zoo.pipeline.api.net import *\n",
    "from zoo.pipeline.nnframes import *\n",
    "from zoo.feature.image.imagePreprocessing import *\n",
    "\n",
    "import random\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from zoo.pipeline.api.keras.metrics import AUC\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pyspark.ml import Pipeline\n",
    "from bigdl.optim.optimizer import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparkConf = SparkConf().setAppName(\"testMutipleLabels\")\n",
    "sc = init_nncontext(sparkConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = create_spark_conf().setAppName(\"testMutipleLabels\")\n",
    "sc = init_nncontext(sparkConf)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mahmood/analytics-zoo/apps/dogs-vs-cats/JeansDatasets/red_shirt/\n",
      "/home/mahmood/analytics-zoo/apps/dogs-vs-cats/JeansDatasets/allJeansImage/\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/mahmood/analytics-zoo/apps/dogs-vs-cats/JeansDatasets/red_shirt/\"\n",
    "print path\n",
    "new_path=\"/home/mahmood/analytics-zoo/apps/dogs-vs-cats/JeansDatasets/allJeansImage/\"\n",
    "print new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.util.common import *\n",
    "from bigdl.transform.vision.image import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/mahmood/analytics-zoo/demo/bigdl_inception-v1_imagenet_0.4.0.model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/home/mahmood/analytics-zoo/apps/dogs-vs-cats/JeansDatasets/allJeansImage/'\n",
    "label_path = '/home/mahmood/analytics-zoo/apps/dogs-vs-cats/AllLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLabel = udf(lambda x: text_to_label(x), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/usr/lib64/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/usr/lib64/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.tslibs.offsets as liboffsets\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as libalgos, ops as libops\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.interval import (\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import internals as libinternals\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, reduction,\n",
      "/usr/lib64/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/usr/lib64/python2.7/site-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/usr/lib64/python2.7/site-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib, writers as libwriters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labelDF=pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_index</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black_jeans_00000000.jpg</td>\n",
       "      <td>black_jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black_jeans_00000001.jpeg</td>\n",
       "      <td>black_jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black_jeans_00000002.jpeg</td>\n",
       "      <td>black_jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black_jeans_00000003.jpg</td>\n",
       "      <td>black_jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black_jeans_00000004.jpg</td>\n",
       "      <td>black_jeans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image_index       labels\n",
       "0   black_jeans_00000000.jpg  black_jeans\n",
       "1  black_jeans_00000001.jpeg  black_jeans\n",
       "2  black_jeans_00000002.jpeg  black_jeans\n",
       "3   black_jeans_00000003.jpg  black_jeans\n",
       "4   black_jeans_00000004.jpg  black_jeans"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlCtx = SQLContext(sc)\n",
    "labelDFsp = sqlCtx.createDataFrame(labelDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'jeans', 'blue', 'dress', 'shirt', 'red']\n",
      "{'blue': 2, 'shirt': 4, 'jeans': 1, 'black': 0, 'dress': 3, 'red': 5}\n"
     ]
    }
   ],
   "source": [
    "label_texts = list(\"\"\"black,jeans,blue,dress,shirt,red\"\"\".replace(\"\\n\", \"\").split(\",\"))\n",
    "print label_texts\n",
    "\n",
    "label_map = {k: v for v, k in enumerate(label_texts)}\n",
    "print label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def text_to_label(text):\n",
    "    arr = [0.0] * len(label_texts)\n",
    "    for l in text.split(\"_\"):\n",
    "        arr[label_map[l]] = 1.0\n",
    "     \n",
    "    return arr\n",
    "print text_to_label(\"black_jeans\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLabel = udf(lambda x: text_to_label(x), ArrayType(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDF11 = labelDFsp.select(\"Image_index\", \"labels\") \\\n",
    "   .withColumn(\"label\", getLabel(col('labels')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         Image_index|               label|\n",
      "+--------------------+--------------------+\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "|black_jeans_00000...|[1.0, 1.0, 0.0, 0...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelDF11.select(\"Image_index\",\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getLabel = udf(lambda x: text_to_label(x), ArrayType(DoubleType()))\n",
    "getName = udf(lambda row: os.path.basename(row[0]), StringType())\n",
    "imageDF = NNImageReader.readImages(image_path, sc, resizeH=300, resizeW=300 ) \\\n",
    "    .withColumn(\"Image_index\", getName(col('image')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelDF = spark.read.load(label_path, format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\") \\\n",
    "   .select(\"Image Index\", \"Finding Labels\") \\\n",
    "   .withColumn(\"label\", getLabel(col('Finding Labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY code start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = imageDF.join(labelDF11, on=\"Image_index\", how=\"inner\")\n",
    "(trainingDF, validationDF) = train_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fine-tune a pre-trained model by removing the last few layers, freezing the first few layers, and adding some new layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createRowToImageFeature\n",
      "creating: createImageResize\n",
      "creating: createImageCenterCrop\n",
      "creating: createImageChannelNormalize\n",
      "creating: createImageMatToTensor\n",
      "creating: createImageFeatureToTensor\n",
      "creating: createChainedPreprocessing\n"
     ]
    }
   ],
   "source": [
    "transformer = ChainedPreprocessing(\n",
    "        [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224),\n",
    "         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Net API to load a pre-trained model, including models saved by Analytics Zoo, BigDL, Torch, Caffe and Tensorflow. Please refer to [Net API Guide](https://analytics-zoo.github.io/master/#APIGuide/PipelineAPI/net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Net.load_bigdl(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the last few layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print all the model layers and you can choose which layer(s) to remove.\n",
    "\n",
    "When a model is loaded using Net, we can use the newGraph(output) api to define a Model with the output specified by the parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "conv1/7x7_s2\n",
      "conv1/relu_7x7\n",
      "pool1/3x3_s2\n",
      "pool1/norm1\n",
      "conv2/3x3_reduce\n",
      "conv2/relu_3x3_reduce\n",
      "conv2/3x3\n",
      "conv2/relu_3x3\n",
      "conv2/norm2\n",
      "pool2/3x3_s2\n",
      "inception_3a/3x3_reduce\n",
      "inception_3a/5x5_reduce\n",
      "inception_3a/relu_3x3_reduce\n",
      "inception_3a/relu_5x5_reduce\n",
      "inception_3a/pool\n",
      "inception_3a/1x1\n",
      "inception_3a/3x3\n",
      "inception_3a/5x5\n",
      "inception_3a/pool_proj\n",
      "inception_3a/relu_pool_proj\n",
      "inception_3a/relu_5x5\n",
      "inception_3a/relu_3x3\n",
      "inception_3a/relu_1x1\n",
      "inception_3a/output\n",
      "inception_3b/3x3_reduce\n",
      "inception_3b/5x5_reduce\n",
      "inception_3b/relu_3x3_reduce\n",
      "inception_3b/relu_5x5_reduce\n",
      "inception_3b/pool\n",
      "inception_3b/1x1\n",
      "inception_3b/3x3\n",
      "inception_3b/5x5\n",
      "inception_3b/pool_proj\n",
      "inception_3b/relu_pool_proj\n",
      "inception_3b/relu_5x5\n",
      "inception_3b/relu_3x3\n",
      "inception_3b/relu_1x1\n",
      "inception_3b/output\n",
      "pool3/3x3_s2\n",
      "inception_4a/3x3_reduce\n",
      "inception_4a/5x5_reduce\n",
      "inception_4a/relu_3x3_reduce\n",
      "inception_4a/relu_5x5_reduce\n",
      "inception_4a/pool\n",
      "inception_4a/1x1\n",
      "inception_4a/3x3\n",
      "inception_4a/5x5\n",
      "inception_4a/pool_proj\n",
      "inception_4a/relu_pool_proj\n",
      "inception_4a/relu_5x5\n",
      "inception_4a/relu_3x3\n",
      "inception_4a/relu_1x1\n",
      "inception_4a/output\n",
      "inception_4b/3x3_reduce\n",
      "inception_4b/5x5_reduce\n",
      "inception_4b/relu_3x3_reduce\n",
      "inception_4b/relu_5x5_reduce\n",
      "inception_4b/pool\n",
      "inception_4b/1x1\n",
      "inception_4b/3x3\n",
      "inception_4b/5x5\n",
      "inception_4b/pool_proj\n",
      "inception_4b/relu_pool_proj\n",
      "inception_4b/relu_5x5\n",
      "inception_4b/relu_3x3\n",
      "inception_4b/relu_1x1\n",
      "inception_4b/output\n",
      "inception_4c/3x3_reduce\n",
      "inception_4c/5x5_reduce\n",
      "inception_4c/relu_3x3_reduce\n",
      "inception_4c/relu_5x5_reduce\n",
      "inception_4c/pool\n",
      "inception_4c/1x1\n",
      "inception_4c/3x3\n",
      "inception_4c/5x5\n",
      "inception_4c/pool_proj\n",
      "inception_4c/relu_pool_proj\n",
      "inception_4c/relu_5x5\n",
      "inception_4c/relu_3x3\n",
      "inception_4c/relu_1x1\n",
      "inception_4c/output\n",
      "inception_4d/3x3_reduce\n",
      "inception_4d/5x5_reduce\n",
      "inception_4d/relu_3x3_reduce\n",
      "inception_4d/relu_5x5_reduce\n",
      "inception_4d/pool\n",
      "inception_4d/1x1\n",
      "inception_4d/3x3\n",
      "inception_4d/5x5\n",
      "inception_4d/pool_proj\n",
      "inception_4d/relu_pool_proj\n",
      "inception_4d/relu_5x5\n",
      "inception_4d/relu_3x3\n",
      "inception_4d/relu_1x1\n",
      "inception_4d/output\n",
      "inception_4e/3x3_reduce\n",
      "inception_4e/5x5_reduce\n",
      "inception_4e/relu_3x3_reduce\n",
      "inception_4e/relu_5x5_reduce\n",
      "inception_4e/pool\n",
      "inception_4e/1x1\n",
      "inception_4e/3x3\n",
      "inception_4e/5x5\n",
      "inception_4e/pool_proj\n",
      "inception_4e/relu_pool_proj\n",
      "inception_4e/relu_5x5\n",
      "inception_4e/relu_3x3\n",
      "inception_4e/relu_1x1\n",
      "inception_4e/output\n",
      "pool4/3x3_s2\n",
      "inception_5a/3x3_reduce\n",
      "inception_5a/5x5_reduce\n",
      "inception_5a/relu_3x3_reduce\n",
      "inception_5a/relu_5x5_reduce\n",
      "inception_5a/pool\n",
      "inception_5a/1x1\n",
      "inception_5a/3x3\n",
      "inception_5a/5x5\n",
      "inception_5a/pool_proj\n",
      "inception_5a/relu_pool_proj\n",
      "inception_5a/relu_5x5\n",
      "inception_5a/relu_3x3\n",
      "inception_5a/relu_1x1\n",
      "inception_5a/output\n",
      "inception_5b/3x3_reduce\n",
      "inception_5b/5x5_reduce\n",
      "inception_5b/relu_3x3_reduce\n",
      "inception_5b/relu_5x5_reduce\n",
      "inception_5b/pool\n",
      "inception_5b/1x1\n",
      "inception_5b/3x3\n",
      "inception_5b/5x5\n",
      "inception_5b/pool_proj\n",
      "inception_5b/relu_pool_proj\n",
      "inception_5b/relu_5x5\n",
      "inception_5b/relu_3x3\n",
      "inception_5b/relu_1x1\n",
      "inception_5b/output\n",
      "pool5/7x7_s1\n",
      "pool5/drop_7x7_s1\n",
      "Viewb5bcd097\n",
      "loss3/classifier\n",
      "prob\n"
     ]
    }
   ],
   "source": [
    "for layer in full_model.layers:\n",
    "    print (layer.name())\n",
    "model = full_model.new_graph([\"pool5/drop_7x7_s1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returning model's output layer is \"pool5/drop_7x7_s1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze some layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We freeze layers from input to pool4/3x3_s2 inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.freeze_up_to([\"pool4/3x3_s2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasInput\n",
      "creating: createZooKerasFlatten\n",
      "creating: createZooKerasDense\n",
      "creating: createZooKerasModel\n"
     ]
    }
   ],
   "source": [
    "inputNode = Input(name=\"input\", shape=(3, 224, 224))\n",
    "inception = model.to_keras()(inputNode)\n",
    "flatten = Flatten()(inception)\n",
    "logits = Dense(6, activation=\"sigmoid\")(flatten)\n",
    "lrModel = Model(inputNode, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a few new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createValidationSummary\n"
     ]
    }
   ],
   "source": [
    "val_summary = ValidationSummary(log_dir=\"/home/mahmood/analytics-zoo/apps/dogs-vs-cats/logDirectroy/log\", app_name=\"testMutipleLabels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createMultiLabelSoftMarginCriterion\n",
      "creating: createSeqToTensor\n",
      "creating: createFeatureLabelPreprocessing\n",
      "creating: createNNEstimator\n",
      "creating: createEveryEpoch\n",
      "creating: createAUC\n"
     ]
    }
   ],
   "source": [
    "classifier = NNEstimator(lrModel, MultiLabelSoftMarginCriterion(), transformer, SeqToTensor([6])) \\\n",
    "     .setLearningRate(0.001).setBatchSize(24).setMaxEpoch(10).setFeaturesCol(\"image\")\\\n",
    "     .setCachingSample(False)\\\n",
    "     .setValidation(EveryEpoch(), validationDF,[AUC()],  24)\n",
    "#\\\n",
    " #    .setValidationSummary(val_summary)\n",
    "#\\\n",
    "    # .setCheckpoint(\"/home/mahmood/analytics-zoo/apps/dogs-vs-cats/logDirectroy/checkpoint\", EveryEpoch(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createToTuple\n",
      "creating: createChainedPreprocessing\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "nnModel = classifier.fit(trainingDF)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+--------------------+\n",
      "|         Image_index|               image|     labels|               label|          prediction|\n",
      "+--------------------+--------------------+-----------+--------------------+--------------------+\n",
      "|black_jeans_00000...|[file:/home/mahmo...|black_jeans|[1.0, 1.0, 0.0, 0...|[0.0024215402, 0....|\n",
      "|black_jeans_00000...|[file:/home/mahmo...|black_jeans|[1.0, 1.0, 0.0, 0...|[6.489417E-4, 0.1...|\n",
      "|blue_dress_000002...|[file:/home/mahmo...| blue_dress|[0.0, 0.0, 1.0, 1...|[0.0055481303, 0....|\n",
      "|blue_jeans_000001...|[file:/home/mahmo...| blue_jeans|[0.0, 1.0, 1.0, 0...|[0.0072195423, 0....|\n",
      "|blue_jeans_000001...|[file:/home/mahmo...| blue_jeans|[0.0, 1.0, 1.0, 0...|[0.013826376, 0.8...|\n",
      "+--------------------+--------------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|         Image_index|               label|          prediction|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|blue_dress_000000...|[0.0, 0.0, 1.0, 1...|[0.008507947, 0.0...|\n",
      "|blue_shirt_000000...|[0.0, 0.0, 1.0, 0...|[0.0052134492, 0....|\n",
      "|blue_shirt_000002...|[0.0, 0.0, 1.0, 0...|[0.011554826, 0.0...|\n",
      "|blue_shirt_000003...|[0.0, 0.0, 1.0, 0...|[8.1048044E-4, 0....|\n",
      "|red_shirt_0000000...|[0.0, 0.0, 0.0, 0...|[0.08511742, 0.06...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nnModel.transform(trainingDF).show(5)\n",
    "\n",
    "predictionDF = nnModel.transform(validationDF).cache()\n",
    "\n",
    "predictionDF.select(\"Image_index\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------AUC  CALCULATION  ----------------------------\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "Lab=predictionDF.select(\"label\") #.collect()\n",
    "Pre=predictionDF.select(\"prediction\") #.collect()\n",
    "\n",
    "\n",
    "#__________________________________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Lab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.array(Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.array(Lab)\n",
    "P=P.reshape(P.shape[0],P.shape[2])\n",
    "Pre1=np.array(Pre)\n",
    "Pre1=Pre1.reshape(Pre1.shape[0],Pre1.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score=roc_auc_score(P, Pre1)\n",
    "n_classes=6\n",
    "\n",
    "#----------------[ Get AUC values ]-------------------------------------\n",
    "def get_auc_values(LabelArray,PredArray): \n",
    "    n_classes=6\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(LabelArray[:, i], PredArray[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return roc_auc,fpr,tpr     \n",
    "\n",
    "roc_auc,fpr, tpr=get_auc_values(P,Pre1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------plot AUC---------------------------------\n",
    "def ploting_AUC(fpr, tpr, label_texts): \n",
    "\n",
    "  #%matplotlib inline\n",
    "    plt.figure()\n",
    "    lw=1\n",
    "    colors = (['aqua', 'darkorange', 'cornflowerblue','red','blue','maroon'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                label='{0} (area = {1:0.2f})'\n",
    "                ''.format(label_texts[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('AUC for multi-class')\n",
    "      \n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "            fancybox=True, shadow=True, ncol=5)\n",
    "    plt.show()\n",
    "\n",
    "ploting_AUC(fpr, tpr, label_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
